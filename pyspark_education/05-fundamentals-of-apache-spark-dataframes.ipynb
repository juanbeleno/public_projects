{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7144f4ec-5ddf-44ef-86d2-c599ba08df2b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Apache Spark Fundamentals: SQL/DataFrames\n",
    "\n",
    "Spark SQL works with DataFrames. A DataFrame is a relational representation of data. It provides functions similar to SQL functions. Also, it allows us to write SQL-type queries.\n",
    "\n",
    "DataFrame are similar to relation tables or DataFrames in python/R, but they have many optimizations that are executed \"hidden\" from the user. There are several ways to create DataFrames from collections, HIVE tables, relational tables, and RDDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6139eff2-0632-4350-9beb-a88ead232a90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, countDistinct, sum, min, max, avg, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fc7ad7e-cbf2-400d-80f8-d8884a83957a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_fire_df = spark.read \\\n",
    "                .format(\"csv\") \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .option(\"inferSchema\", \"true\") \\\n",
    "                .load(\"/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36746e6c-3548-440f-9bb7-bf1cc00a15bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Call Number', 'Unit ID', 'Incident Number', 'CallType', 'Call Date', 'Watch Date', 'Call Final Disposition', 'Available DtTm', 'Address', 'City', 'Zipcode of Incident', 'Battalion', 'Station Area', 'Box', 'OrigPriority', 'Priority', 'Final Priority', 'ALS Unit', 'Call Type Group', 'NumAlarms', 'UnitType', 'Unit sequence in call dispatch', 'Fire Prevention District', 'Supervisor District', 'Neighborhood', 'Location', 'RowID', 'Delay']\n"
     ]
    }
   ],
   "source": [
    "# Get the columns of the DataFrame\n",
    "columns = raw_fire_df.columns\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31d72339-afbd-4293-a814-502b757816ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CallNumber', 'UnitID', 'IncidentNumber', 'CallType', 'CallDate', 'WatchDate', 'CallFinalDisposition', 'AvailableDtTm', 'Address', 'City', 'ZipcodeofIncident', 'Battalion', 'StationArea', 'Box', 'OrigPriority', 'Priority', 'FinalPriority', 'ALSUnit', 'CallTypeGroup', 'NumAlarms', 'UnitType', 'Unitsequenceincalldispatch', 'FirePreventionDistrict', 'SupervisorDistrict', 'Neighborhood', 'Location', 'RowID', 'Delay']\n"
     ]
    }
   ],
   "source": [
    "# We can modify the Columns using a common preprocessing\n",
    "def preprocess_column_names(column):\n",
    "    new_column = column.replace(\" \", \"\")\n",
    "    return new_column\n",
    "\n",
    "new_columns = [preprocess_column_names(x) for x in columns]\n",
    "print(new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e2c1d3d-3346-45c8-8013-d325aed32b57",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CallNumber', 'UnitID', 'IncidentNumber', 'CallType', 'CallDate', 'WatchDate', 'CallFinalDisposition', 'AvailableDtTm', 'Address', 'City', 'ZipcodeofIncident', 'Battalion', 'StationArea', 'Box', 'OrigPriority', 'Priority', 'FinalPriority', 'ALSUnit', 'CallTypeGroup', 'NumAlarms', 'UnitType', 'Unitsequenceincalldispatch', 'FirePreventionDistrict', 'SupervisorDistrict', 'Neighborhood', 'Location', 'RowID', 'Delay']\n"
     ]
    }
   ],
   "source": [
    "# Assign the new columns to the DataFrame\n",
    "mapping = dict(zip(columns, new_columns))\n",
    "fire_df = raw_fire_df.select([col(c).alias(mapping.get(c, c)) for c in columns])\n",
    "print(fire_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f28e2bad-cd56-415a-9ae2-f21a04b49aa3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[19]: [('CallNumber', 'int'),\n ('UnitID', 'string'),\n ('IncidentNumber', 'int'),\n ('CallType', 'string'),\n ('CallDate', 'date'),\n ('WatchDate', 'date'),\n ('CallFinalDisposition', 'string'),\n ('AvailableDtTm', 'string'),\n ('Address', 'string'),\n ('City', 'string'),\n ('ZipcodeofIncident', 'int'),\n ('Battalion', 'string'),\n ('StationArea', 'string'),\n ('Box', 'string'),\n ('OrigPriority', 'string'),\n ('Priority', 'string'),\n ('FinalPriority', 'int'),\n ('ALSUnit', 'boolean'),\n ('CallTypeGroup', 'string'),\n ('NumAlarms', 'int'),\n ('UnitType', 'string'),\n ('Unitsequenceincalldispatch', 'int'),\n ('FirePreventionDistrict', 'string'),\n ('SupervisorDistrict', 'string'),\n ('Neighborhood', 'string'),\n ('Location', 'string'),\n ('RowID', 'string'),\n ('Delay', 'double')]"
     ]
    }
   ],
   "source": [
    "fire_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e9845bc-6a97-46cc-ae65-9467479da38c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# where is an alias for filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e00fb280-7283-4e29-a2db-bf3978003f32",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CallNumber', 'UnitID', 'IncidentNumber', 'CallType', 'CallDate', 'CallFinalDisposition', 'AvailableDtTm', 'Address', 'City', 'ZipcodeofIncident', 'Battalion', 'StationArea', 'Box', 'OrigPriority', 'Priority', 'FinalPriority', 'ALSUnit', 'CallTypeGroup', 'NumAlarms', 'UnitType', 'Unitsequenceincalldispatch', 'FirePreventionDistrict', 'SupervisorDistrict', 'Neighborhood', 'Location', 'RowID', 'Delay']\n"
     ]
    }
   ],
   "source": [
    "# We can drop a particular column in a DataFrame\n",
    "new_fire_df = fire_df.drop(\"WatchDate\")\n",
    "print(new_fire_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd41e175-9785-43ae-9a97-6cb82c98e7a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ZipcodeofIncident</th><th>num_incidents</th><th>sum_delays</th><th>max_delays</th><th>min_delays</th><th>avg_delays</th></tr></thead><tbody><tr><td>94158</td><td>9273</td><td>136712.0333333335</td><td>1503.7666666666667</td><td>0.016666666666666666</td><td>6.520343078806386</td></tr><tr><td>94130</td><td>10552</td><td>150000.56666666665</td><td>1016.15</td><td>0.03333333333333333</td><td>5.497345403014976</td></tr><tr><td>94129</td><td>4663</td><td>60397.600000000006</td><td>123.98333333333333</td><td>0.016666666666666666</td><td>4.9510287728502345</td></tr><tr><td>94131</td><td>36826</td><td>342028.2166666665</td><td>1497.8</td><td>0.016666666666666666</td><td>4.1626489870100345</td></tr><tr><td>94124</td><td>110049</td><td>956264.15</td><td>1739.4333333333334</td><td>0.016666666666666666</td><td>4.161940730488675</td></tr><tr><td>94132</td><td>49815</td><td>446596.94999999984</td><td>628.55</td><td>0.016666666666666666</td><td>4.119746042581453</td></tr><tr><td>94134</td><td>58918</td><td>500654.63333333284</td><td>1126.5</td><td>0.016666666666666666</td><td>4.084042755680269</td></tr><tr><td>94127</td><td>21731</td><td>189892.5833333333</td><td>958.8166666666667</td><td>0.016666666666666666</td><td>4.068574622015583</td></tr><tr><td>94121</td><td>52793</td><td>472129.3000000003</td><td>508.85</td><td>0.016666666666666666</td><td>4.037363605267661</td></tr><tr><td>94105</td><td>49427</td><td>420187.3333333328</td><td>683.2666666666667</td><td>0.06666666666666667</td><td>4.018662509524123</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         94158,
         9273,
         136712.0333333335,
         1503.7666666666667,
         0.016666666666666666,
         6.520343078806386
        ],
        [
         94130,
         10552,
         150000.56666666665,
         1016.15,
         0.03333333333333333,
         5.497345403014976
        ],
        [
         94129,
         4663,
         60397.600000000006,
         123.98333333333333,
         0.016666666666666666,
         4.9510287728502345
        ],
        [
         94131,
         36826,
         342028.2166666665,
         1497.8,
         0.016666666666666666,
         4.1626489870100345
        ],
        [
         94124,
         110049,
         956264.15,
         1739.4333333333334,
         0.016666666666666666,
         4.161940730488675
        ],
        [
         94132,
         49815,
         446596.94999999984,
         628.55,
         0.016666666666666666,
         4.119746042581453
        ],
        [
         94134,
         58918,
         500654.63333333284,
         1126.5,
         0.016666666666666666,
         4.084042755680269
        ],
        [
         94127,
         21731,
         189892.5833333333,
         958.8166666666667,
         0.016666666666666666,
         4.068574622015583
        ],
        [
         94121,
         52793,
         472129.3000000003,
         508.85,
         0.016666666666666666,
         4.037363605267661
        ],
        [
         94105,
         49427,
         420187.3333333328,
         683.2666666666667,
         0.06666666666666667,
         4.018662509524123
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ZipcodeofIncident",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "num_incidents",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "sum_delays",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "max_delays",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "min_delays",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "avg_delays",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aggregation functions and alias\n",
    "agg_df = (\n",
    "    new_fire_df\n",
    "        .where(\"ZipcodeofIncident IS NOT NULL\")\n",
    "        .groupBy(\"ZipcodeofIncident\")\n",
    "        .agg(\n",
    "            countDistinct(\"CallNumber\").alias(\"num_incidents\"),\n",
    "            sum(\"Delay\").alias(\"sum_delays\"),\n",
    "            max(\"Delay\").alias(\"max_delays\"),\n",
    "            min(\"Delay\").alias(\"min_delays\"),\n",
    "            avg(\"Delay\").alias(\"avg_delays\"),\n",
    "        ).sort(desc(col(\"avg_delays\")))\n",
    ")\n",
    "display(agg_df.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "005f53cd-03d8-4819-a633-811b3d552539",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[31]: '\\ndf1 = df1.join(df2, df1[\"id\"] == df2[\"id\"], \"inner\")\\n'"
     ]
    }
   ],
   "source": [
    "# JOIN types\n",
    "\"\"\"\n",
    "df1 = df1.join(df2, df1[\"id\"] == df2[\"id\"], \"inner\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05-fundamentals-of-apache-spark-dataframes",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
