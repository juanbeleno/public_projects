{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Common Readability Prize using a regression model\n\nWe need to predict the readability score of a text. I'm going to treat this problem as a regression problem.","metadata":{}},{"cell_type":"code","source":"!nvidia-smi\n!nvcc -V\n\n# Verify pytorch is using the GPU\nimport torch\nprint(f'Torch: {torch.__version__}')\n\n# If there's a GPU available...\nif torch.cuda.is_available():    \n\n    # Tell PyTorch to use the GPU.    \n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\n# If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:38:07.431637Z","iopub.execute_input":"2021-06-03T20:38:07.432084Z","iopub.status.idle":"2021-06-03T20:38:08.872139Z","shell.execute_reply.started":"2021-06-03T20:38:07.432048Z","shell.execute_reply":"2021-06-03T20:38:08.871176Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Thu Jun  3 20:38:08 2021       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   37C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2020 NVIDIA Corporation\nBuilt on Wed_Jul_22_19:09:09_PDT_2020\nCuda compilation tools, release 11.0, V11.0.221\nBuild cuda_11.0_bu.TC445_37.28845127_0\nTorch: 1.7.0\nThere are 1 GPU(s) available.\nWe will use the GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndata_dir = '../input/commonlitreadabilityprize/'\ntrain_filepath = f'{data_dir}train.csv'\ntest_filepath = f'{data_dir}test.csv'\nunigrams_filepath = '../input/gwordlist/frequency-all.txt'\nbigrams_filepath = '../input/peter-norvig-count-2wtxt/count_2w.txt'\n\ntrain_data = pd.read_csv(train_filepath)\n\n\n# License and URL\nfrom urllib.parse import urlsplit\n\ndef get_base_url(url):\n    url = str(url)\n    split_url = urlsplit(url)\n    return split_url.netloc\n\n#license_dict = {x: index for index, x in enumerate(train_data['license'].unique())}\nlicense_dict = {\n    'CC BY 4.0': 0,\n    'CC BY-SA 3.0 and GFDL': 1,\n    'CC BY-SA 3.0': 2,\n    'CC BY-NC-SA 2.0': 3,\n    'CC BY 3.0': 4\n}\ntrain_data['license'] = train_data['license'].replace(license_dict)\ntrain_data['url_legal'] = train_data['url_legal'].apply(get_base_url)\n#url_dict = {x: index for index, x in enumerate(train_data['url_legal'].unique())}\nurl_dict = {\n    '': 0,\n    'simple.wikipedia.org': 1,\n    'kids.frontiersin.org': 2,\n    'en.wikipedia.org': 3,\n    'www.africanstorybook.org': 4,\n    'www.commonlit.org': 5,\n    'www.digitallibrary.io': 6,\n    'freekidsbooks.org': 7,\n    'en.wikibooks.org': 8,\n    'static.ehe.osu.edu': 9\n}\ntrain_data['url_legal'] = train_data['url_legal'].replace(url_dict)\n\ntest_data = pd.read_csv(test_filepath)\ntest_data['license'] = test_data['license'].map(license_dict)\ntest_data['url_legal'] = test_data['url_legal'].map(url_dict)\n\n# Removing 1% of high loss labels after training\nhigh_loss_labels = [\n    \"04ade0eb2\", \"bcd734621\", \"76f92b721\", \"03b761fd9\", \"afeb324bd\", \"9cbc92ce1\",\n    \"83f9c17b9\", \"62dceff46\", \"78006971c\", \"23ff6b3c9\", \"6ee4f1df3\", \"15e2e9e7a\",\n    \"99a602911\", \"dd54ca86d\", \"f28a4261d\", \"47e98a5c8\", \"4cf4a2fa3\", \"f04e03fd8\",\n    \"02817cbd1\", \"dc05f5cbd\", \"f317805ab\", \"9ea0d2788\", \"322e67244\", \"8cc328cc3\",\n    \"060fc57c6\", \"c913c40e9\", \"6923a71bd\", \"3c1674b21\", \"04fe69def\", \"551e0fc0b\"\n]\n#train_data = train_data[~train_data['id'].isin(high_loss_labels)]\n\n# Convert datasets to list of dictionaries\ntrain_data = train_data.to_dict('records')\ntest_data = test_data.to_dict('records')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:38:08.875251Z","iopub.execute_input":"2021-06-03T20:38:08.875529Z","iopub.status.idle":"2021-06-03T20:38:08.961141Z","shell.execute_reply.started":"2021-06-03T20:38:08.875500Z","shell.execute_reply":"2021-06-03T20:38:08.960398Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# I'm using the unigrams available at https://github.com/hackerb9/gwordlist\nraw_unigrams = pd.read_csv(unigrams_filepath, sep='\\t', )\nraw_unigrams.columns = ['gold_content', 'count', 'percent', 'cumulative']\nunigrams = pd.DataFrame(\n    raw_unigrams.gold_content.str.split(' ', 1).tolist(),\n    columns = ['ranking','unigram'])\nunigrams['unigram'] = unigrams['unigram'].str.strip()\nunigrams['ranking'] = pd.to_numeric(unigrams[\"ranking\"])\nunigrams_dict = dict(zip(unigrams['unigram'], unigrams['ranking']))\ndel unigrams\ndel raw_unigrams","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:38:08.964253Z","iopub.execute_input":"2021-06-03T20:38:08.964525Z","iopub.status.idle":"2021-06-03T20:38:50.924817Z","shell.execute_reply.started":"2021-06-03T20:38:08.964499Z","shell.execute_reply":"2021-06-03T20:38:50.923970Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3166: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n","output_type":"stream"}]},{"cell_type":"code","source":"# I'm using the bigrams available at https://norvig.com/ngrams/count_2w.txt\nraw_bigrams = pd.read_csv(bigrams_filepath, sep='\\t', header=None)\nraw_bigrams.columns = ['bigram', 'frequency']\nraw_bigrams.sort_values(by='frequency', inplace=True, ignore_index=True, ascending=False)\nbigrams_dict = {x['bigram']: index + 1 for index, x in enumerate(raw_bigrams.to_dict('records'))}\ndel raw_bigrams","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:38:50.927128Z","iopub.execute_input":"2021-06-03T20:38:50.927624Z","iopub.status.idle":"2021-06-03T20:38:52.876964Z","shell.execute_reply.started":"2021-06-03T20:38:50.927588Z","shell.execute_reply":"2021-06-03T20:38:52.876069Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Features","metadata":{}},{"cell_type":"markdown","source":"## Manual Features","metadata":{}},{"cell_type":"code","source":"import spacy\nimport numpy as np\nfrom nltk.util import ngrams\nimport nltk\nnlp = spacy.load(\"en_core_web_lg\")\n\ndef get_manual_features(text, license, url):\n    # Inspiration: https://arxiv.org/pdf/2103.04083v1.pdf\n    \n    if url not in url_dict:\n        url = len(url_dict)\n\n    if license not in license_dict:\n        license = len(license_dict)\n\n    doc = nlp(text)\n    difficulty_embedding = []\n    unigram_embedding_size = 256\n    bigram_embedding_size = 128\n    NUM_UNIGRAMS = 7919828\n\n    num_words = len(doc)\n    num_sentences = len(list(doc.sents))\n    num_characters = len(text)\n    num_pronouns = 0\n    num_verbs = 0\n    num_adjectives = 0\n    num_adverbs = 0\n    num_nouns = 0\n    num_determinants = 0\n    num_punctuation = 0\n    num_long_words = 0\n    num_letters = 0\n    num_unigrams_without_difficulty = 0\n    words = {}\n\n    for index, token in enumerate(doc):\n        word_difficulty = unigrams_dict.get(token.text, None)\n        if word_difficulty:\n            difficulty_embedding.append(word_difficulty/NUM_UNIGRAMS)\n        else:\n            num_unigrams_without_difficulty += 1\n        if token.pos_ == 'PRON':\n            num_pronouns += 1\n        if token.pos_ == 'VERB':\n            num_verbs += 1\n        if token.pos_ == 'ADJ':\n            num_adjectives += 1\n        if token.pos_ == 'ADV':\n            num_adverbs += 1\n        if token.pos_ in ['NOUN', 'PROPN']:\n            num_nouns += 1\n        if token.pos_ == 'DET':\n            num_determinants += 1\n        if token.pos_ == 'PUNCT':\n            num_punctuation += 1\n        if len(token.text) > 6:\n            num_long_words += 1\n        if token.is_alpha:\n            num_letters += len(token.text)\n        words[token.text] = 1\n    \n    # Difficulty of bigrams\n    num_bigrams_without_difficulty = 0\n    lower_text = text\n    lower_text = lower_text.lower()\n    tokens = nltk.word_tokenize(lower_text)\n    bigrams = [' '.join(x) for x in ngrams(tokens, 2)]\n    bigram_difficulty_embedding = []\n    NUM_BIGRAMS = len(bigrams_dict)\n\n    for bigram in bigrams:\n        bigram_difficulty = bigrams_dict.get(bigram, None)\n        if bigram_difficulty:\n            bigram_difficulty_embedding.append(bigram_difficulty / NUM_BIGRAMS)\n        else:\n            num_bigrams_without_difficulty += 1\n\n    # Document level features\n    words_by_sentence = num_words / num_sentences\n    characters_by_word = num_characters / num_words\n    letters_by_word = num_letters / num_words\n    long_words_by_word = num_long_words / num_words\n    unique_words_by_word = len(words) / num_words\n    avg_difficulty = sum(difficulty_embedding) / len(difficulty_embedding)\n    avg_bigram_difficulty = sum(bigram_difficulty_embedding) / len(bigram_difficulty_embedding)\n\n    # Difficulty features\n    #difficulty_embedding = list(set(difficulty_embedding))\n    difficulty_embedding.sort(reverse=True)\n    difficulty_embedding = difficulty_embedding[:unigram_embedding_size] \n    difficulty_embedding = difficulty_embedding + [0] * (unigram_embedding_size - len(difficulty_embedding))\n    #bigram_difficulty_embedding = list(set(bigram_difficulty_embedding))\n    bigram_difficulty_embedding.sort(reverse=True)\n    bigram_difficulty_embedding = bigram_difficulty_embedding[:bigram_embedding_size]\n    bigram_difficulty_embedding = bigram_difficulty_embedding + [0] * (bigram_embedding_size - len(bigram_difficulty_embedding))\n\n    manual_embedding = [\n        license, url, num_words, num_sentences, num_characters, num_pronouns,\n        num_verbs, num_adjectives, num_adverbs, num_nouns,\n        num_determinants, num_punctuation,\n        num_long_words, num_letters, words_by_sentence, characters_by_word,\n        letters_by_word, long_words_by_word, unique_words_by_word,\n        unique_words_by_word, avg_difficulty, avg_bigram_difficulty,\n        num_unigrams_without_difficulty, num_bigrams_without_difficulty\n    ]\n    manual_embedding.extend(difficulty_embedding)\n    manual_embedding.extend(bigram_difficulty_embedding)\n    return np.array(manual_embedding)\ntext_sample = '''\nWhile I was hailing the brig, I spied a tract of water lying between us, where no great waves came, but which yet boiled white all over and bristled in the moon with rings and bubbles. Sometimes the whole tract swung to one side, like the tail of a live serpent; sometimes, for a glimpse, it would all disappear and then boil up again. What it was I had no guess, which for the time increased my fear of it; but I now know it must have been the roost or tide-race, which had carried me away so fast and tumbled me about so cruelly, and at last, as if tired of that play, had flung out me and the spare yard upon its landward margin.\nI now lay quite becalmed, and began to feel that a man can die of cold as well as of drowning. The shores of Earraid were close in; I could see in the moonlight the dots of heather and the sparkling of the mica in the rocks.\n'''\nfeatures = get_manual_features(text_sample, 0, 0)\nprint(features.shape)\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:38:52.878430Z","iopub.execute_input":"2021-06-03T20:38:52.878769Z","iopub.status.idle":"2021-06-03T20:39:03.582385Z","shell.execute_reply.started":"2021-06-03T20:38:52.878734Z","shell.execute_reply":"2021-06-03T20:39:03.581492Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(408,)\n[5.00000000e+00 1.00000000e+01 1.98000000e+02 7.00000000e+00\n 8.59000000e+02 1.50000000e+01 2.40000000e+01 1.00000000e+01\n 2.00000000e+01 3.10000000e+01 2.50000000e+01 2.10000000e+01\n 2.00000000e+01 6.64000000e+02 2.82857143e+01 4.33838384e+00\n 3.35353535e+00 1.01010101e-01 6.11111111e-01 6.11111111e-01\n 7.94848684e-04 1.64017255e-01 1.30000000e+01 9.40000000e+01\n 7.65414350e-02 8.20169327e-03 6.04230294e-03 5.68774978e-03\n 5.34557064e-03 4.12925634e-03 3.89010973e-03 2.56886892e-03\n 2.55535853e-03 2.28578196e-03 2.21974518e-03 2.11393480e-03\n 1.81897890e-03 1.61556539e-03 1.55760958e-03 1.54296280e-03\n 1.38285831e-03 1.32894300e-03 1.24245122e-03 1.19447038e-03\n 1.16669200e-03 1.16454549e-03 9.81586974e-04 8.16179341e-04\n 7.59233660e-04 7.52667861e-04 6.74383333e-04 5.53168579e-04\n 5.53168579e-04 5.51400864e-04 5.34355039e-04 5.01778574e-04\n 5.00389655e-04 4.64404025e-04 3.68189814e-04 3.43568067e-04\n 3.42684210e-04 3.40411433e-04 2.25636213e-04 1.68816798e-04\n 1.44826378e-04 1.34093821e-04 1.32452371e-04 1.03285071e-04\n 9.67192722e-05 8.96484116e-05 8.51028583e-05 8.14411626e-05\n 7.96734475e-05 7.10874024e-05 6.16174998e-05 6.08599076e-05\n 5.78295387e-05 4.34352867e-05 3.92685296e-05 3.88897335e-05\n 3.51017724e-05 3.00511577e-05 2.96723616e-05 2.82834425e-05\n 2.63894620e-05 2.43692161e-05 2.18439087e-05 1.75508862e-05\n 1.69195594e-05 1.64144979e-05 1.52781096e-05 1.40154559e-05\n 1.38891905e-05 1.37629252e-05 1.35103944e-05 1.35103944e-05\n 1.30053329e-05 1.28790676e-05 1.25002715e-05 1.16164139e-05\n 1.16164139e-05 1.16164139e-05 1.14901485e-05 1.12376178e-05\n 1.09850870e-05 1.07325563e-05 1.02274948e-05 1.01012295e-05\n 9.84869873e-06 9.21737189e-06 8.08098358e-06 7.57592210e-06\n 7.57592210e-06 7.32339137e-06 6.94459526e-06 6.94459526e-06\n 6.69206452e-06 6.56579916e-06 6.06073768e-06 5.80820695e-06\n 5.80820695e-06 5.68194158e-06 5.42941084e-06 5.05061474e-06\n 5.05061474e-06 5.05061474e-06 4.67181863e-06 4.54555326e-06\n 4.54555326e-06 4.29302253e-06 4.29302253e-06 4.29302253e-06\n 3.91422642e-06 3.53543031e-06 3.28289958e-06 3.28289958e-06\n 3.28289958e-06 3.03036884e-06 3.03036884e-06 3.03036884e-06\n 3.03036884e-06 3.03036884e-06 3.03036884e-06 2.27277663e-06\n 2.14651126e-06 2.14651126e-06 2.02024589e-06 1.89398053e-06\n 1.89398053e-06 1.89398053e-06 1.76771516e-06 1.76771516e-06\n 1.76771516e-06 1.76771516e-06 1.38891905e-06 1.38891905e-06\n 1.26265368e-06 1.26265368e-06 8.83857579e-07 8.83857579e-07\n 8.83857579e-07 8.83857579e-07 7.57592210e-07 7.57592210e-07\n 7.57592210e-07 7.57592210e-07 6.31326842e-07 6.31326842e-07\n 5.05061474e-07 5.05061474e-07 5.05061474e-07 5.05061474e-07\n 5.05061474e-07 5.05061474e-07 5.05061474e-07 5.05061474e-07\n 3.78796105e-07 3.78796105e-07 3.78796105e-07 3.78796105e-07\n 3.78796105e-07 3.78796105e-07 3.78796105e-07 3.78796105e-07\n 3.78796105e-07 2.52530737e-07 2.52530737e-07 2.52530737e-07\n 2.52530737e-07 2.52530737e-07 2.52530737e-07 2.52530737e-07\n 2.52530737e-07 2.52530737e-07 2.52530737e-07 2.52530737e-07\n 2.52530737e-07 1.26265368e-07 1.26265368e-07 1.26265368e-07\n 1.26265368e-07 1.26265368e-07 1.26265368e-07 1.26265368e-07\n 1.26265368e-07 1.26265368e-07 1.26265368e-07 1.26265368e-07\n 1.26265368e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 9.75425866e-01 8.65926567e-01 8.65926567e-01 8.60367093e-01\n 7.66159842e-01 7.57076806e-01 7.48143932e-01 7.27767340e-01\n 6.42681538e-01 6.21142067e-01 6.01257866e-01 5.75126241e-01\n 4.96462470e-01 4.12333513e-01 3.92424867e-01 3.89393696e-01\n 3.49757995e-01 3.40500353e-01 2.95175969e-01 2.79168034e-01\n 2.74851759e-01 2.51803686e-01 2.23671069e-01 1.97029592e-01\n 1.89029117e-01 1.85271583e-01 1.78849552e-01 1.75612345e-01\n 1.66923920e-01 1.56705942e-01 1.54498914e-01 1.52029976e-01\n 1.45803505e-01 1.42622172e-01 1.22748448e-01 1.18222644e-01\n 1.16200700e-01 1.15673388e-01 1.10225662e-01 9.52339379e-02\n 8.83369768e-02 6.93188247e-02 6.52854120e-02 5.21899161e-02\n 4.19335238e-02 3.99988825e-02 3.91817236e-02 3.26165150e-02\n 3.12720441e-02 3.11707723e-02 3.04793301e-02 2.81081723e-02\n 2.63167085e-02 2.41201573e-02 2.13194672e-02 2.09353327e-02\n 1.74676454e-02 1.54736379e-02 1.49079125e-02 1.41780568e-02\n 1.40488479e-02 1.39790053e-02 1.21456359e-02 1.19256316e-02\n 8.88747652e-03 7.39633605e-03 7.25665077e-03 6.64203549e-03\n 6.40107837e-03 4.97978055e-03 4.69691784e-03 4.57818535e-03\n 4.45945285e-03 4.23246426e-03 4.22897213e-03 3.91817236e-03\n 3.01371011e-03 1.65177854e-03 1.57145950e-03 1.55749097e-03\n 1.49114046e-03 1.48764833e-03 1.00573408e-03 6.53028726e-04\n 5.09851305e-04 3.42228958e-04 2.68894181e-04 1.92067272e-04\n 1.29208892e-04 7.33347767e-05 4.53977189e-05 2.09527934e-05\n 2.09527934e-05 1.74606611e-05 6.98426445e-06 6.98426445e-06\n 6.98426445e-06 3.49213223e-06 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n","output_type":"stream"}]},{"cell_type":"code","source":"for index in range(len(train_data)):\n    train_data[index]['manual_embedding'] = get_manual_features(\n        train_data[index]['excerpt'], train_data[index]['license'], train_data[index]['url_legal'])\n\nfor index in range(len(test_data)):\n    test_data[index]['manual_embedding'] = get_manual_features(\n        test_data[index]['excerpt'], test_data[index]['license'], test_data[index]['url_legal'])\n\n# Free some memory\ndel unigrams_dict\ndel bigrams_dict","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:39:03.583697Z","iopub.execute_input":"2021-06-03T20:39:03.584203Z","iopub.status.idle":"2021-06-03T20:40:32.364141Z","shell.execute_reply.started":"2021-06-03T20:39:03.584165Z","shell.execute_reply":"2021-06-03T20:40:32.363218Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Text embeddings using Language Models: ROBERTA\n\nROBERTA produces useful sentence embeddings for the `<s>` token (equivalent to the [CLS] token in BERT). However, we can use average pooling to increase the semantics of embeddings.","metadata":{}},{"cell_type":"code","source":"# Mean Pooling - Take attention mask into account for correct averaging\n# Source: https://huggingface.co/sentence-transformers/bert-base-nli-mean-tokens\ndef mean_pooling(token_embeddings, attention_mask):\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n    return sum_embeddings / sum_mask\n\ndef get_lm_embeddings(text, tokenizer, language_model, mask_words=True):\n    tokens = tokenizer(\n        text, return_tensors='pt', padding='max_length', max_length=350\n    )\n    # Source: https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/159505\n    if mask_words:\n        input_ids = np.array(tokens['input_ids'])\n        uniform_dist = np.random.uniform(0, 1, input_ids.shape[0])\n        # Do not mask <s> and </s> tokens\n        uniform_dist[0] = 1\n        uniform_dist[input_ids.shape[0] - 1] = 1\n        # Replace 5% random tokens by <mask> token\n        input_ids[uniform_dist<0.05] = 50264\n        tokens['input_ids'] = torch.LongTensor(input_ids)\n    tokens.to(device)\n    outputs = language_model(output_hidden_states=True, **tokens)\n    token_embeddings = outputs.last_hidden_state\n    hidden_states = outputs.hidden_states\n\n    # Concatenate the average pooling of each of the 13 layers\n    attention_mask = tokens['attention_mask'].to(device)\n    avg_embedding = None\n    for layer_id in range(13):\n        hidden_embeddings = hidden_states[layer_id]\n        layer_avg_embedding = mean_pooling(hidden_embeddings, tokens['attention_mask'].to(device)).detach().to('cpu').numpy()\n        if avg_embedding is None:\n            avg_embedding = layer_avg_embedding[0]\n        else:\n            avg_embedding = np.concatenate((layer_avg_embedding[0], avg_embedding), axis=0)\n    return avg_embedding","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:40:32.365618Z","iopub.execute_input":"2021-06-03T20:40:32.365962Z","iopub.status.idle":"2021-06-03T20:40:32.375672Z","shell.execute_reply.started":"2021-06-03T20:40:32.365923Z","shell.execute_reply":"2021-06-03T20:40:32.374869Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Data Generators","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nimport numpy as np\n\nclass CommonLitReadabilityDataset(Dataset):\n    def __init__(self, dataset):\n        self.dataset = dataset\n    \n    def __len__(self):\n        return len(self.dataset)\n    \n    def __getitem__(self, index):\n        data = self.dataset[index]\n        target = 0.0\n        if 'target' in data:\n            target = data['target']\n\n        response = {\n            'lm_embedding': data['lm_embedding'],\n            'manual_embedding': data['manual_embedding'],\n            'target': np.array([target])\n        }\n\n        return response\n\ndef custom_collate(batch):\n    \"\"\"Get features and targets\"\"\"\n    # Features\n    lm_embedding = torch.from_numpy(np.array([item['lm_embedding'] for item in batch]))\n    lm_embedding = torch.squeeze(lm_embedding)\n    manual_embedding = torch.from_numpy(np.array([item['manual_embedding'] for item in batch]))\n    manual_embedding = torch.squeeze(manual_embedding)\n\n    # Targets\n    target = torch.FloatTensor([item['target'] for item in batch])\n\n    return {\n        'lm_embedding': lm_embedding,\n        'manual_embedding': manual_embedding,\n        'target': target\n    }","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:40:32.378023Z","iopub.execute_input":"2021-06-03T20:40:32.378542Z","iopub.status.idle":"2021-06-03T20:40:32.391119Z","shell.execute_reply.started":"2021-06-03T20:40:32.378507Z","shell.execute_reply":"2021-06-03T20:40:32.390263Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Get Data Loaders","metadata":{}},{"cell_type":"code","source":"def load_embeddings_for_dataset(dataset, tokenizer, language_model, mask_words=True):\n    \"\"\"Get LM embeddings for a dataset\"\"\"\n    for index in range(len(dataset)):\n        dataset[index]['lm_embedding'] = get_lm_embeddings(\n            dataset[index]['excerpt'], tokenizer, language_model, mask_words)\n    return dataset\n\ndef get_data_loader(data, indices, shuffle=True, batch_size=32):\n    \"\"\"Get a Data Loader for a given dataset\"\"\"\n    dataset = [data[idx].copy() for idx in indices]\n    ds = CommonLitReadabilityDataset(dataset)\n    loader = DataLoader(\n        ds, batch_size=batch_size, num_workers=0, collate_fn=custom_collate,\n        pin_memory=True, shuffle=shuffle)\n    return loader","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:40:32.392710Z","iopub.execute_input":"2021-06-03T20:40:32.393065Z","iopub.status.idle":"2021-06-03T20:40:32.404124Z","shell.execute_reply.started":"2021-06-03T20:40:32.393031Z","shell.execute_reply":"2021-06-03T20:40:32.403420Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nfrom torch.nn import MSELoss\nimport torch\n\nclass CommonLitReadabilityModel(nn.Module):\n    def __init__(self, EMBEDDING_SIZE=768, hidden_size=768):\n        super().__init__()\n        DROPOUT_RATE = 0.0\n        NUM_MANUAL_FEATURES = 408\n\n        self.dense = nn.Linear(EMBEDDING_SIZE * 13 + NUM_MANUAL_FEATURES, hidden_size)\n        self.dropout = nn.Dropout(DROPOUT_RATE)\n        self.target_proj = nn.Linear(hidden_size, 1)\n    \n    def forward(\n        self, manual_embedding, lm_embedding, target=None):\n        x = torch.cat((manual_embedding, lm_embedding), dim=-1)\n        x = self.dropout(x)\n        x = self.dense(x)\n        x = torch.tanh(x)\n        x = self.dropout(x)\n\n        # Computing the logits\n        logits_target = self.target_proj(x)\n\n        # Computing the loss\n        loss = None\n        if target is not None:\n            loss_fct = MSELoss()\n            loss = loss_fct(logits_target.view(-1, 1), target)\n            loss = torch.sqrt(loss)\n\n        return logits_target, loss","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:40:32.405370Z","iopub.execute_input":"2021-06-03T20:40:32.405754Z","iopub.status.idle":"2021-06-03T20:40:32.415581Z","shell.execute_reply.started":"2021-06-03T20:40:32.405717Z","shell.execute_reply":"2021-06-03T20:40:32.414638Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from copy import deepcopy\nfrom fastprogress import master_bar, progress_bar\nfrom sklearn.metrics import mean_squared_error\nfrom transformers import (\n    AdamW, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n)\nimport torch.optim.lr_scheduler as lr_scheduler\nimport torch.nn as nn\nimport torch\nimport os\n\n\ndef get_trained_model(config, train_indices=None, val_loader=None, embedding_size=768):\n    \"\"\"Train a model\"\"\"\n    train_loader = get_data_loader(train_data, train_indices, batch_size=config['batch_size'])\n\n    model = CommonLitReadabilityModel(embedding_size, config['hidden_size'])\n    model.to(device)\n\n    # Karphaty LR = 3e-4\n    optimizer = AdamW(\n        model.parameters(),\n        lr=config['lr'], # args.learning_rate - default is 5e-5.\n        weight_decay=config['weight_decay']\n    )\n\n    mb = master_bar(range(config['num_epochs']))\n\n    # Total number of training steps\n    TOTAL_STEPS = len(train_loader) * config['num_epochs']\n\n    # Create the learning rate scheduler.\n    # Source: https://www.kaggle.com/rhtsingh/commonlit-readability-prize-roberta-torch-fit\n    if config['scheduler_name'] == 'linear':\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=int(config['warmup_steps'] * TOTAL_STEPS),\n            num_training_steps = TOTAL_STEPS)\n    elif config['scheduler_name'] == 'cosine':\n        scheduler = lr_scheduler.CosineAnnealingLR(\n            optimizer,\n            T_max=TOTAL_STEPS\n        )\n    elif config['scheduler_name'] == 'cosine_warmup':\n        scheduler = get_cosine_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=int(config['warmup_steps'] * TOTAL_STEPS),\n            num_training_steps=TOTAL_STEPS\n        )\n\n    # Define variables to keep track of models\n    best_model_state = None\n    best_rmse = 3.0\n    best_loss = []\n    best_optimizer = None\n    \n    for epoch in mb:\n        # Reset the total loss for this epoch in training phase\n        total_train_loss = 0\n        num_train_samples = 0\n\n        # Training phase\n        model.train()\n        for index, batch in enumerate(progress_bar(train_loader, parent=mb)):\n            # Extract features\n            b_manual_embedding = batch['manual_embedding'].to(device).float()\n            b_lm_embedding = batch['lm_embedding'].to(device).float()\n            b_target = batch['target'].to(device).float()\n\n            # Reset the optimizer: Don't reuse info about the last batches\n            # It seems it is safer to zero_grad() the model instead of the optimizer\n            # Source: https://discuss.pytorch.org/t/model-zero-grad-or-optimizer-zero-grad/28426/6\n            model.zero_grad()\n\n            # Calculate the forwards pass and the loss\n            _, loss = model(b_manual_embedding, b_lm_embedding, b_target)\n\n            # backward + optimize + schedule only if the model is in training phase\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n            # Accumulate the training loss\n            total_train_loss += loss.item()\n            num_train_samples += list(batch['target'].size())[0]\n            \n            if index % 10 == 0:\n                # Reset the total loss for this epoch in validation phase.\n                total_val_loss = 0\n                num_val_samples = 0\n\n                # Tracking variables\n                val_labels = []\n                val_predictions = []\n                local_loss = []\n\n                # Validation phase\n                model.eval()\n                for batch in progress_bar(val_loader, parent=mb):\n                    # Extract features\n                    b_manual_embedding = batch['manual_embedding'].to(device).float()\n                    b_lm_embedding = batch['lm_embedding'].to(device).float()\n                    b_target = batch['target'].to(device).float()\n\n                    # There is no need to compute the graph for the forward pass\n                    # because we only need it for backprop (training)\n                    with torch.no_grad():\n                        # Calculate the forward pass and the loss\n                        logits, loss = model(b_manual_embedding, b_lm_embedding, b_target)\n\n                    # Accumulate the validation loss\n                    total_val_loss += loss.item()\n                    local_loss.append(loss.item())\n                    num_val_samples += list(batch['target'].size())[0]\n\n                    # Move labels and logits to CPU\n                    labels = b_target.to('cpu').numpy()\n                    val_labels.extend(labels.tolist())\n                    predictions = logits.to('cpu').numpy()\n                    val_predictions.extend(predictions.tolist())\n                # Report validation metrics\n                val_rmse = mean_squared_error(val_labels, val_predictions, squared=False)\n\n                # Save best model\n                if val_rmse < best_rmse:\n                    best_rmse = val_rmse\n                    best_model_state = deepcopy(model.state_dict())\n                    best_loss = local_loss\n                    best_optimizer = deepcopy(optimizer.state_dict())\n                model.train()\n\n    # Load the best model\n    best_model = CommonLitReadabilityModel(embedding_size, config['hidden_size'])\n    best_model.load_state_dict(best_model_state)\n    best_model.to(device)\n    return best_model, best_rmse, best_loss","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:40:32.417025Z","iopub.execute_input":"2021-06-03T20:40:32.417650Z","iopub.status.idle":"2021-06-03T20:40:36.733717Z","shell.execute_reply.started":"2021-06-03T20:40:32.417610Z","shell.execute_reply":"2021-06-03T20:40:36.732880Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def generate_predictions_from_model(model, test_loader):\n    \"\"\"Get predictions from a model\"\"\"\n    test_predictions = []\n    model.eval()\n    for batch in test_loader:\n        # Extract features\n        b_manual_embedding = batch['manual_embedding'].to(device).float()\n        b_lm_embedding = batch['lm_embedding'].to(device).float()\n        b_target = batch['target'].to(device).float()\n\n        # There is no need to compute the graph for the forward pass\n        # because we only need it for backprop (training)\n        with torch.no_grad():\n            # Calculate the forward pass and the loss\n            logits, _ = model(b_manual_embedding, b_lm_embedding)\n\n        # Move logits to CPU\n        predictions = logits.to('cpu').numpy()\n        test_predictions.extend(predictions.tolist())\n    return np.array(test_predictions)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:40:36.735054Z","iopub.execute_input":"2021-06-03T20:40:36.735418Z","iopub.status.idle":"2021-06-03T20:40:36.744394Z","shell.execute_reply.started":"2021-06-03T20:40:36.735380Z","shell.execute_reply":"2021-06-03T20:40:36.743626Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"def get_loss_df(loss_array, val_idx):\n    return pd.DataFrame({\n        'id': [train_data[index]['id'] for index in val_idx],\n        'loss': loss_array\n    })","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:40:36.745582Z","iopub.execute_input":"2021-06-03T20:40:36.746101Z","iopub.status.idle":"2021-06-03T20:40:36.755958Z","shell.execute_reply.started":"2021-06-03T20:40:36.746064Z","shell.execute_reply":"2021-06-03T20:40:36.755238Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom transformers import RobertaTokenizer, RobertaModel\nfrom scipy.stats import loguniform\n\n\ndef get_predictions(model_name, embedding_size=768, num_folds=5):\n    global train_data\n    global test_data\n\n    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n    language_model = RobertaModel.from_pretrained(model_name)\n    language_model.to(device)\n    \n    # Calculating LM embeddings for a dataset\n    train_data = load_embeddings_for_dataset(\n        train_data, tokenizer, language_model)\n    test_data = load_embeddings_for_dataset(\n        test_data, tokenizer, language_model, mask_words=False)\n    \n    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n    predictions = np.zeros(len(test_data))\n    loss_df = None\n    sum_rmse = 0\n\n    for index, (train_idx, val_idx) in enumerate(kf.split(train_data)):\n        print(f'----------------- KFold = {index} ----------------------')\n        # Create Data Loaders\n        val_loader = get_data_loader(\n            train_data, val_idx, shuffle=False, batch_size=1)\n        test_loader = get_data_loader(\n            test_data, range(len(test_data)), shuffle=False)\n\n        # Train the model with hyperparameters\n        best_model = None\n        best_loss_array = []\n        best_rmse = 3.0\n        num_hyperparameter_samples = 10\n        for index in range(num_hyperparameter_samples):\n            config = {\n                'batch_size': int(np.random.randint(4, 10)),\n                'hidden_size': np.random.choice([768, 896, 1024, 1280, 1536, 1792, 2048]),\n                'lr': loguniform(8e-6, 7e-5).rvs(1)[0],\n                'weight_decay': np.random.uniform(0, 5e-2),\n                'num_epochs': np.random.randint(6, 14),\n                'scheduler_name': np.random.choice(['linear', 'cosine', 'cosine_warmup']),\n                'warmup_steps': np.random.uniform(0, 0.3)\n            }\n            model, rmse, loss_array = get_trained_model(\n                config, train_idx, val_loader, embedding_size=embedding_size)\n            \n            # Print metrics\n            print(f'Hyperparameters: {config}')\n            print(f'RMSE: {rmse}')\n            print('-------------')\n            \n            # Getting the model with the best hyperparameters\n            if rmse < best_rmse:\n                best_model = model\n                best_loss_array = loss_array\n                best_rmse = rmse\n\n        print(f'Best RMSE in this fold: {best_rmse}')\n\n        sum_rmse += best_rmse\n        if index == 0:\n            loss_df = get_loss_df(best_loss_array, val_idx)\n        else:\n            loss_df = pd.concat([loss_df, get_loss_df(best_loss_array, val_idx)])\n\n        # Get predictions\n        local_predictions = generate_predictions_from_model(best_model, test_loader)\n        local_predictions = local_predictions.reshape(-1)\n        predictions += local_predictions\n    print('--------------------------------------------')\n    print(f'CV RMSE: {sum_rmse / num_folds}')\n    return (predictions / num_folds), loss_df","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:40:36.757348Z","iopub.execute_input":"2021-06-03T20:40:36.757709Z","iopub.status.idle":"2021-06-03T20:40:36.970757Z","shell.execute_reply.started":"2021-06-03T20:40:36.757673Z","shell.execute_reply":"2021-06-03T20:40:36.969959Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Generating the outputs","metadata":{}},{"cell_type":"code","source":"predictions, loss_df = get_predictions('../input/robertalarge', embedding_size=1024)\ntest_ids = [x['id'] for x in test_data]\nsubmission = pd.DataFrame({'id': test_ids,'target': predictions})\nsubmission.to_csv('submission.csv',index=False)\n\n# Ordering samples by loss\n# Source: https://twitter.com/karpathy/status/1311884485676294151\nloss_df.sort_values(by='loss', ascending=False, inplace=True)\nloss_df.to_csv('loss.csv', index=False)\nloss_df","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:40:36.971940Z","iopub.execute_input":"2021-06-03T20:40:36.972458Z","iopub.status.idle":"2021-06-03T23:06:58.602424Z","shell.execute_reply.started":"2021-06-03T20:40:36.972420Z","shell.execute_reply":"2021-06-03T23:06:58.601480Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"----------------- KFold = 0 ----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 4, 'hidden_size': 2048, 'lr': 8.748689697732768e-06, 'weight_decay': 0.004245788207908829, 'num_epochs': 9, 'scheduler_name': 'cosine', 'warmup_steps': 0.10505472954335983}\nRMSE: 0.5066691802865106\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 4, 'hidden_size': 1024, 'lr': 4.86147908735894e-05, 'weight_decay': 0.03304807365607703, 'num_epochs': 11, 'scheduler_name': 'cosine', 'warmup_steps': 0.24823091272585526}\nRMSE: 0.4979806868149192\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 9, 'hidden_size': 2048, 'lr': 3.50505580927901e-05, 'weight_decay': 0.03913888570350431, 'num_epochs': 11, 'scheduler_name': 'linear', 'warmup_steps': 0.17109979761006525}\nRMSE: 0.49857411734320517\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 6, 'hidden_size': 1536, 'lr': 1.8393148242755756e-05, 'weight_decay': 0.046867982030249694, 'num_epochs': 11, 'scheduler_name': 'cosine_warmup', 'warmup_steps': 0.1757376538627818}\nRMSE: 0.499610433362183\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 6, 'hidden_size': 1536, 'lr': 9.453732619537727e-06, 'weight_decay': 0.03696072905751617, 'num_epochs': 11, 'scheduler_name': 'cosine_warmup', 'warmup_steps': 0.01992667071380484}\nRMSE: 0.5051983595465287\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 8, 'hidden_size': 1024, 'lr': 1.9396630498151293e-05, 'weight_decay': 0.014514432548442702, 'num_epochs': 10, 'scheduler_name': 'cosine_warmup', 'warmup_steps': 0.17655301861633826}\nRMSE: 0.5036248891106291\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 6, 'hidden_size': 1536, 'lr': 3.169240293362089e-05, 'weight_decay': 0.046662754539125675, 'num_epochs': 8, 'scheduler_name': 'cosine', 'warmup_steps': 0.20157921143778298}\nRMSE: 0.502835181587306\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 7, 'hidden_size': 1536, 'lr': 3.895895882361935e-05, 'weight_decay': 0.04819304716472199, 'num_epochs': 9, 'scheduler_name': 'cosine_warmup', 'warmup_steps': 0.029598888261904887}\nRMSE: 0.5008730864843179\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 6, 'hidden_size': 768, 'lr': 4.551821463147036e-05, 'weight_decay': 0.00735471528780069, 'num_epochs': 7, 'scheduler_name': 'cosine', 'warmup_steps': 0.23678793671504653}\nRMSE: 0.502290502429344\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 8, 'hidden_size': 1792, 'lr': 3.8578517958472054e-05, 'weight_decay': 0.018229248292004403, 'num_epochs': 9, 'scheduler_name': 'cosine', 'warmup_steps': 0.18438404602820765}\nRMSE: 0.5012800942160024\n-------------\nBest RMSE in this fold: 0.4979806868149192\n----------------- KFold = 1 ----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 8, 'hidden_size': 768, 'lr': 3.5477549297560426e-05, 'weight_decay': 0.0004948255422831838, 'num_epochs': 6, 'scheduler_name': 'cosine_warmup', 'warmup_steps': 0.06263851104736624}\nRMSE: 0.5162361538913575\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 7, 'hidden_size': 1024, 'lr': 3.9999843850448205e-05, 'weight_decay': 0.021433679084563326, 'num_epochs': 10, 'scheduler_name': 'cosine', 'warmup_steps': 0.0958546409463325}\nRMSE: 0.5074048550510822\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 6, 'hidden_size': 1792, 'lr': 1.3924325146914747e-05, 'weight_decay': 0.013496314910723612, 'num_epochs': 8, 'scheduler_name': 'linear', 'warmup_steps': 0.13022211676073428}\nRMSE: 0.5106800626019734\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 8, 'hidden_size': 1536, 'lr': 1.5082806136707312e-05, 'weight_decay': 0.0137664329684909, 'num_epochs': 13, 'scheduler_name': 'cosine', 'warmup_steps': 0.2530133618752249}\nRMSE: 0.509098218786536\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 9, 'hidden_size': 1024, 'lr': 1.4722864024058411e-05, 'weight_decay': 0.03524908144259702, 'num_epochs': 6, 'scheduler_name': 'cosine', 'warmup_steps': 0.26671178037777893}\nRMSE: 0.5234145114650307\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 4, 'hidden_size': 1024, 'lr': 3.2402803103667186e-05, 'weight_decay': 0.029409438837385362, 'num_epochs': 6, 'scheduler_name': 'cosine_warmup', 'warmup_steps': 0.10909099847267352}\nRMSE: 0.5157627610822956\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 5, 'hidden_size': 768, 'lr': 4.403581868506273e-05, 'weight_decay': 0.04497062569111342, 'num_epochs': 6, 'scheduler_name': 'cosine', 'warmup_steps': 0.07499738402305879}\nRMSE: 0.5206544261528179\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 4, 'hidden_size': 896, 'lr': 1.2583231380129073e-05, 'weight_decay': 0.046249791139150884, 'num_epochs': 12, 'scheduler_name': 'linear', 'warmup_steps': 0.2721467610647034}\nRMSE: 0.5063282994205504\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 4, 'hidden_size': 896, 'lr': 8.915979439538967e-06, 'weight_decay': 0.00140078878210278, 'num_epochs': 9, 'scheduler_name': 'linear', 'warmup_steps': 0.24679667061815394}\nRMSE: 0.5140121299612722\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 7, 'hidden_size': 1280, 'lr': 2.2549937333726784e-05, 'weight_decay': 0.03628806588544357, 'num_epochs': 6, 'scheduler_name': 'cosine', 'warmup_steps': 0.049526019645682325}\nRMSE: 0.5229443838633221\n-------------\nBest RMSE in this fold: 0.5063282994205504\n----------------- KFold = 2 ----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 9, 'hidden_size': 1280, 'lr': 8.30380973333873e-06, 'weight_decay': 0.012384542787557535, 'num_epochs': 6, 'scheduler_name': 'cosine_warmup', 'warmup_steps': 0.12854772584008414}\nRMSE: 0.5197040503547814\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 7, 'hidden_size': 2048, 'lr': 5.94426575642029e-05, 'weight_decay': 0.03737005537206673, 'num_epochs': 10, 'scheduler_name': 'cosine_warmup', 'warmup_steps': 0.22735931742235616}\nRMSE: 0.4981763361723056\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 8, 'hidden_size': 896, 'lr': 8.600425421016075e-06, 'weight_decay': 0.04270199591151267, 'num_epochs': 8, 'scheduler_name': 'cosine', 'warmup_steps': 0.15990707917831776}\nRMSE: 0.5115493454961639\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 5, 'hidden_size': 768, 'lr': 6.345827191501508e-05, 'weight_decay': 0.013286383350653292, 'num_epochs': 13, 'scheduler_name': 'cosine', 'warmup_steps': 0.157498632963248}\nRMSE: 0.4967094074487955\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 6, 'hidden_size': 896, 'lr': 1.0249753788753402e-05, 'weight_decay': 0.04110117774968526, 'num_epochs': 11, 'scheduler_name': 'cosine', 'warmup_steps': 0.1814086541328904}\nRMSE: 0.5016072924455439\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 6, 'hidden_size': 1280, 'lr': 1.9055718638400564e-05, 'weight_decay': 0.00768206363301981, 'num_epochs': 11, 'scheduler_name': 'cosine_warmup', 'warmup_steps': 0.2737426017433533}\nRMSE: 0.4968877179611011\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 8, 'hidden_size': 1792, 'lr': 5.160404676911979e-05, 'weight_decay': 8.171588245448614e-05, 'num_epochs': 6, 'scheduler_name': 'linear', 'warmup_steps': 0.13820679169706077}\nRMSE: 0.4999441770525927\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 8, 'hidden_size': 1024, 'lr': 6.129337316294255e-05, 'weight_decay': 0.018889324980580338, 'num_epochs': 13, 'scheduler_name': 'cosine_warmup', 'warmup_steps': 0.15122501953546796}\nRMSE: 0.4977932745258283\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 9, 'hidden_size': 1024, 'lr': 1.3443538880908077e-05, 'weight_decay': 0.04200517328017774, 'num_epochs': 10, 'scheduler_name': 'cosine', 'warmup_steps': 0.06348614061686582}\nRMSE: 0.49926185589276545\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 9, 'hidden_size': 1280, 'lr': 1.736619249185331e-05, 'weight_decay': 0.01484904883830106, 'num_epochs': 7, 'scheduler_name': 'linear', 'warmup_steps': 0.1992322018252112}\nRMSE: 0.5032434785362141\n-------------\nBest RMSE in this fold: 0.4967094074487955\n----------------- KFold = 3 ----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 5, 'hidden_size': 1536, 'lr': 2.1758974513877916e-05, 'weight_decay': 0.003345761141172954, 'num_epochs': 11, 'scheduler_name': 'cosine_warmup', 'warmup_steps': 0.13911050720361692}\nRMSE: 0.5168468686717327\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 7, 'hidden_size': 1792, 'lr': 4.61869723825839e-05, 'weight_decay': 0.03994917050733861, 'num_epochs': 12, 'scheduler_name': 'linear', 'warmup_steps': 0.24846212097882378}\nRMSE: 0.5144203655663465\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 8, 'hidden_size': 1792, 'lr': 1.265128332500921e-05, 'weight_decay': 0.0396060273583875, 'num_epochs': 8, 'scheduler_name': 'cosine', 'warmup_steps': 0.20315723323584658}\nRMSE: 0.5232528260616728\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 5, 'hidden_size': 768, 'lr': 3.8547586679010496e-05, 'weight_decay': 0.028985615527994748, 'num_epochs': 6, 'scheduler_name': 'cosine_warmup', 'warmup_steps': 0.12205467176545304}\nRMSE: 0.5220968633337245\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 4, 'hidden_size': 768, 'lr': 1.767519419942351e-05, 'weight_decay': 0.02894133463653958, 'num_epochs': 11, 'scheduler_name': 'cosine_warmup', 'warmup_steps': 0.15309907331954814}\nRMSE: 0.5159306031475913\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 8, 'hidden_size': 1792, 'lr': 9.267751706192318e-06, 'weight_decay': 0.004318358832349978, 'num_epochs': 8, 'scheduler_name': 'cosine', 'warmup_steps': 0.10551949746662818}\nRMSE: 0.5273700922068304\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 5, 'hidden_size': 768, 'lr': 1.1046079231264008e-05, 'weight_decay': 0.0452930799575003, 'num_epochs': 13, 'scheduler_name': 'cosine_warmup', 'warmup_steps': 0.03310971456854917}\nRMSE: 0.5150867274822962\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 8, 'hidden_size': 1536, 'lr': 1.5568253552614374e-05, 'weight_decay': 0.0158080696654828, 'num_epochs': 11, 'scheduler_name': 'cosine_warmup', 'warmup_steps': 0.2595951792834051}\nRMSE: 0.5156468691670459\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 8, 'hidden_size': 768, 'lr': 2.724276886872198e-05, 'weight_decay': 0.013445295202269931, 'num_epochs': 6, 'scheduler_name': 'cosine_warmup', 'warmup_steps': 0.2856203235346349}\nRMSE: 0.5201253876992531\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 9, 'hidden_size': 896, 'lr': 5.841468444320575e-05, 'weight_decay': 0.004901881272604808, 'num_epochs': 9, 'scheduler_name': 'cosine_warmup', 'warmup_steps': 0.24770474019515062}\nRMSE: 0.5154642458631632\n-------------\nBest RMSE in this fold: 0.5144203655663465\n----------------- KFold = 4 ----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 7, 'hidden_size': 1536, 'lr': 6.752259723554071e-05, 'weight_decay': 0.03449615422727958, 'num_epochs': 6, 'scheduler_name': 'cosine', 'warmup_steps': 0.014263622722490587}\nRMSE: 0.5240104043395085\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 9, 'hidden_size': 1024, 'lr': 1.2440844520563466e-05, 'weight_decay': 0.017633578526945755, 'num_epochs': 13, 'scheduler_name': 'linear', 'warmup_steps': 0.21036119884228602}\nRMSE: 0.5187535934496875\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 5, 'hidden_size': 1536, 'lr': 1.2852983174754012e-05, 'weight_decay': 0.045545918202767564, 'num_epochs': 10, 'scheduler_name': 'cosine', 'warmup_steps': 0.09195042281844595}\nRMSE: 0.5180052634813648\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 8, 'hidden_size': 1024, 'lr': 2.029848825066884e-05, 'weight_decay': 0.007177684912383015, 'num_epochs': 11, 'scheduler_name': 'cosine', 'warmup_steps': 0.2509877646721011}\nRMSE: 0.5179403465578645\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 6, 'hidden_size': 1280, 'lr': 1.9147402583610943e-05, 'weight_decay': 0.02813516155396439, 'num_epochs': 8, 'scheduler_name': 'linear', 'warmup_steps': 0.13869784383705938}\nRMSE: 0.5196396997878777\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 5, 'hidden_size': 1024, 'lr': 1.8141786847665872e-05, 'weight_decay': 0.01695064066791705, 'num_epochs': 12, 'scheduler_name': 'cosine', 'warmup_steps': 0.22136253256341412}\nRMSE: 0.518635572920111\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 5, 'hidden_size': 1024, 'lr': 1.2252701959714999e-05, 'weight_decay': 0.028373042098492774, 'num_epochs': 8, 'scheduler_name': 'cosine_warmup', 'warmup_steps': 0.0922344284477524}\nRMSE: 0.5200845445903509\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 4, 'hidden_size': 1536, 'lr': 1.2132093459294584e-05, 'weight_decay': 0.004253160790899435, 'num_epochs': 6, 'scheduler_name': 'cosine', 'warmup_steps': 0.17539112207886923}\nRMSE: 0.5245911143066301\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 4, 'hidden_size': 896, 'lr': 1.0401291696853708e-05, 'weight_decay': 0.04511981099300953, 'num_epochs': 13, 'scheduler_name': 'cosine_warmup', 'warmup_steps': 0.14703105146791415}\nRMSE: 0.5200062053541403\n-------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Hyperparameters: {'batch_size': 4, 'hidden_size': 1536, 'lr': 1.3272207946288699e-05, 'weight_decay': 0.030757515329971744, 'num_epochs': 7, 'scheduler_name': 'linear', 'warmup_steps': 0.17985072578004174}\nRMSE: 0.5239829100884746\n-------------\nBest RMSE in this fold: 0.5179403465578645\n--------------------------------------------\nCV RMSE: 0.5066758211616952\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"            id      loss\n529  bcd734621  1.976578\n215  03b761fd9  1.975299\n526  04ade0eb2  1.945604\n377  76f92b721  1.920907\n175  4cf4a2fa3  1.651317\n..         ...       ...\n346  a21bfa111  0.000364\n439  a852fb41d  0.000306\n135  e882f463d  0.000082\n19   3723e3a8f  0.000052\n258  1de2b5e2c  0.000047\n\n[2834 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>529</th>\n      <td>bcd734621</td>\n      <td>1.976578</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>03b761fd9</td>\n      <td>1.975299</td>\n    </tr>\n    <tr>\n      <th>526</th>\n      <td>04ade0eb2</td>\n      <td>1.945604</td>\n    </tr>\n    <tr>\n      <th>377</th>\n      <td>76f92b721</td>\n      <td>1.920907</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>4cf4a2fa3</td>\n      <td>1.651317</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>346</th>\n      <td>a21bfa111</td>\n      <td>0.000364</td>\n    </tr>\n    <tr>\n      <th>439</th>\n      <td>a852fb41d</td>\n      <td>0.000306</td>\n    </tr>\n    <tr>\n      <th>135</th>\n      <td>e882f463d</td>\n      <td>0.000082</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>3723e3a8f</td>\n      <td>0.000052</td>\n    </tr>\n    <tr>\n      <th>258</th>\n      <td>1de2b5e2c</td>\n      <td>0.000047</td>\n    </tr>\n  </tbody>\n</table>\n<p>2834 rows × 2 columns</p>\n</div>"},"metadata":{}}]}]}